# Ask me
## Рябинин Максим Константинович, группа 154

### 1. Цель проектной работы
  
  Изучить, воспроизвести и при возможности улучшить функционал нейронной сети, описанной в [статье](https://arxiv.org/pdf/1506.07285.pdf). В конечном итоге программный продукт будет представлять из себя приложение, принимающее некоторый контекст и релевантный ему вопрос на естественном языке и возвращающее ответ (также на естественном языке) на этот вопрос с учётом контекста. В настоящее время глубокое обучение с использованием рекуррентных нейронных сетей является активно развивающейся отраслью, поэтому разработка нейронной сети, способной отвечать на задаваемые на естественном языке вопросы, представляет достаточно большой интерес как с точки зрения науки, так и из практических соображений. Вне всякого сомнения, решаемая задача является актуальной, так как конечный результат возможно будет применить на практике во множестве областей, в которых требуется взаимодействие с человеком, начиная с персонализированных помощников и заканчивая чат-ботами служб технической поддержки или интернет-магазинов.

### 2. Предыдущие работы на данную тематику

Посвящённых решению задачи ответов на вопросы на естественном языке нейронных сетей на момент начала работы над проектом существовало уже достаточно большое количество, например: MemN2N, Dynamic Memory Networks

### 3. Архитектура

Были проведены эксперименты на архитектуре, описанной в статье, однако на всех задачах датасета модель давала не очень высокое качество (в терминах точности ответа), поэтому была создана сеть немного отличающейся структуры: входной контекст и вопрос переводятся в векторное представление (инициализированное GloVe), затем обрабатываются с помощью рекуррентных нейронных сетей (GRU). Полученные векторы конкатенируются и подаются на вход ещё одной нейронной сети, затем её выход копируется 3 раза (чтобы ограничить размер выходного предложения 3 словами), и после ещё одного рекуррентного слоя, проходя через слой Softmax, относятся к одному из классов — слов в словаре. Оптимизируются веса с помощью Adam, также между рекуррентными слоями находятся Dropout и BatchNormalization-слои.

### 4. Достигнутые результаты

На обучающей выборке достигнута точность 99%, на валидационной — 97. На значительную часть вопросов при ручной оценке сеть отвечает корректно, однако при смешивании типов задач доля правильных ответов падает.

### 5. Инструкции по записи


  
